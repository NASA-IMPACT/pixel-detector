{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploying model into AWS cloud environment using Sagemaker.\n",
    "\n",
    "Steps:\n",
    "\n",
    "Model Deployment:\n",
    "- [ ] Login to sagemaker endpoint. \n",
    "- [ ] Convert keras to proto buf format from h5\n",
    "- [ ] Push updated model to S3 bucket\n",
    "- [ ] Deploy an endpoint in sagemaker\n",
    "\n",
    "Inference process:\n",
    "- [ ] Establish a lambda function triggered by API gateway (Code provided)\n",
    "- [ ] Notebook entry to generate s3 signed urls\n",
    "- [ ] Upload file to s3 using signed urls\n",
    "- [ ] Infer endpoint to infer on the uploaded file\n",
    "- [ ] Visualize the image and results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upgrade available version of sagemaker\n",
    "\n",
    "!pip install -U sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sagemaker and tensorflow model to load the model from s3 bucket.\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker.tensorflow import TensorFlowModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow imports needed for model conversion.\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.compat.v1.keras.backend as K\n",
    "\n",
    "from tensorflow.python.saved_model import builder\n",
    "from tensorflow.python.saved_model.signature_def_utils import predict_signature_def\n",
    "from tensorflow.python.saved_model import tag_constants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Account related constants\n",
    "\n",
    "BUCKET = \"smoke-dataset-bucket\"\n",
    "EXECUTION_ROLE = 'arn:aws:iam::574347909231:role/igarss-sagemaker-role'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filename = <model filename> # smoke_wmts_ref_3layer.h5.tar.gz\n",
    "framework_version = <tensorflow version> # 2.9.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TensorFlowModel(\n",
    "    model_data=f\"s3://{BUCKET}/{model_filename}\",\n",
    "    framework_version=framework_version,\n",
    "    role=EXECUTION_ROLE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_VERSION = '1'\n",
    "EXPORT_DIRECTORY = 'export/Servo/{}'\n",
    "\n",
    "\n",
    "def convert_to_proto_buf(model_name)\n",
    "    loaded_model = load_model(model_name)\n",
    "    model_version = '1'\n",
    "    export_dir =  EXPORT_DIRECTORY.format(model_version)\n",
    "    builder = builder.SavedModelBuilder(export_dir)\n",
    "    tf.compat.v1.disable_eager_execution()\n",
    "    signature = predict_signature_def(\n",
    "    inputs={\"inputs\": loaded_model.input}, outputs={\"score\": loaded_model.output})\n",
    "    builder.add_meta_graph_and_variables(\n",
    "    sess=K.get_session(), tags=[tag_constants.SERVING], signature_def_map={\"serving_default\": signature})\n",
    "    builder.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'export/Servo/1/'\n",
    "!saved_model_cli show --all --dir {model_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "model_archive = 'model.tar.gz'\n",
    "with tarfile.open(model_archive, mode='w:gz') as archive:\n",
    "    archive.add('export', recursive=True) \n",
    "\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker import Session\n",
    "role = get_execution_role()\n",
    "sess = Session()\n",
    "bucket = sess.default_bucket()\n",
    "    \n",
    "    \n",
    "# upload model artifacts to S3\n",
    "model_data = sess.upload_data(path=model_archive, key_prefix='model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)  # This notebook runs on TensorFlow 1.15.x or earlier\n",
    "tf_framework_version = tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow.serving import Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_type = 'ml.t2.medium'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_model = Model(model_data=model_data, \n",
    "                 framework_version='2.8',\n",
    "                 role=role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "uncompiled_predictor = sm_model.deploy(\n",
    "        initial_instance_count=1, \n",
    "        instance_type=instance_type, \n",
    "        endpoint_name=\"<yourname>-sagemaker-endpoint\"\n",
    "    )   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncompiled_predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.randn(1, 256, 256, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data = np.random.randn(1, 256, 256, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployed_model_preds = uncompiled_predictor.predict(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing deployed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.asarray(deployed_model_preds['predictions']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_model_preds = loaded_model.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference = deployed_model_preds['predictions'] - original_model_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
