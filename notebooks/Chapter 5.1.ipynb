{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3ca1130-19c1-4bc4-bfbe-a1c1d087c09d",
   "metadata": {},
   "source": [
    "# Install conda using miniconda\n",
    "We will be using python and tensorflow for training. For this we need to create an environment we can use across nodes. We will be using miniconda to create a python virtual environment for our experiments.\n",
    "\n",
    "## Training using High Performance Computing and Tensorflow\n",
    "1. Download Miniconda from https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
    "2. Install conda using miniconda script we downloaded\n",
    "3. Make sure you can use the python from the conda environment\n",
    "4. Create a virtual environment \n",
    "5. Update environment variables\n",
    "6. Folder structure and files we will be using\n",
    "7. Update configuration for training\n",
    "8. Update batch_job file.\n",
    "9. Submit Job \n",
    "10. Check progress\n",
    "11. Test saved model\n",
    "\n",
    "## Use cloud computing for inferencing\n",
    "1. Push trained model to AWS environment using boto3 (Share credentials before this step)\n",
    "2. Access Setup environments in sagemaker\n",
    "3. Load model in sagemaker\n",
    "4. deploy model\n",
    "5. test deployed model\n",
    "6. Deploy API endpoint to interact with model\n",
    "7. Interact with API endpoint to get inferences from the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e771ee6a-3231-4174-a1de-5881d7a5d9a2",
   "metadata": {},
   "source": [
    "## Download Miniconda from https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "374e44b4-2101-42e0-8260-7cb075ea306d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-06-03 21:10:41--  https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
      "Resolving repo.anaconda.com (repo.anaconda.com)... 104.16.131.3, 104.16.130.3, 2606:4700::6810:8203, ...\n",
      "Connecting to repo.anaconda.com (repo.anaconda.com)|104.16.131.3|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 76607678 (73M) [application/x-sh]\n",
      "Saving to: ‘Miniconda3-latest-Linux-x86_64.sh’\n",
      "\n",
      "Miniconda3-latest-L 100%[===================>]  73.06M   153MB/s    in 0.5s    \n",
      "\n",
      "2022-06-03 21:10:42 (153 MB/s) - ‘Miniconda3-latest-Linux-x86_64.sh’ saved [76607678/76607678]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70164300-f584-4d32-9938-3ea6efb4728e",
   "metadata": {},
   "source": [
    "## Install conda using the downloaded miniconda shell script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b18c800-4ad6-42a6-b338-b1c72a1a8eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anaconda3-2019.03-Linux-x86_64.sh  shared\n",
      "Miniconda3-latest-Linux-x86_64.sh  Untitled.ipynb\n"
     ]
    }
   ],
   "source": [
    "!./Miniconda3-latest-Linux-x86_64.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5783e3d5-1a5e-4a7a-98b6-c3f1574bc67d",
   "metadata": {},
   "source": [
    "### Check if the installation updated your bashrc to auto use python from conda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c2c4600-e356-4613-9f2e-69a2145339f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# ******************************************************************************\n",
      "# bash environment file in $HOME\n",
      "# Please see:\n",
      "# http://www.fz-juelich.de/ias/jsc/EN/Expertise/Datamanagement/OnlineStorage/JUST/FAQ/just-FAQ_node.html\n",
      "# for more information and possible modifications to this file\n",
      "# ******************************************************************************\n",
      "\n",
      "# Source global definitions: Copied from CentOS 7 /etc/skel/.bashrc\n",
      "if [ -f /etc/bashrc ]; then\n",
      "        . /etc/bashrc\n",
      "fi\n",
      "\n",
      "#\n",
      "# >>> conda initialize >>>\n",
      "# !! Contents within this block are managed by 'conda init' !!\n",
      "__conda_setup=\"$('/p/project/training2206/anaconda3/bin/conda' 'shell.bash' 'hook' 2> /dev/null)\"\n",
      "if [ $? -eq 0 ]; then\n",
      "    eval \"$__conda_setup\"\n",
      "else\n",
      "    if [ -f \"/p/project/training2206/anaconda3/etc/profile.d/conda.sh\" ]; then\n",
      "        . \"/p/project/training2206/anaconda3/etc/profile.d/conda.sh\"\n",
      "    else\n",
      "        export PATH=\"/p/project/training2206/anaconda3/bin:$PATH\"\n",
      "    fi\n",
      "fi\n",
      "unset __conda_setup\n",
      "# <<< conda initialize <<<\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!cat ~/.bashrc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3b96b9-db5b-40fd-8422-43bbac01dda2",
   "metadata": {},
   "source": [
    "## Folder Structure\n",
    "\n",
    "All of the project related files are located at `/p/project/training2206/<user>/`. (Replace user with the identifier provided for you)\n",
    "\n",
    "Change directory to the aforementioned directory.\n",
    "\n",
    "Check for `pixel-detector` folder in the directory. If it is not present in, you can use git to download it from https://github.com/nasa-impact/pixel-detector using `git clone https://github.com/nasa-impact/pixel-detector.git`\n",
    "\n",
    "Once cloned, change directory into pixel-detector folder using `cd pixel-detector`\n",
    "\n",
    "Following is the folder structure for the code:\n",
    "```\n",
    "|> code\n",
    "    |> lib\n",
    "        |> data_utils: `Contains files to rasterize files and create dataset`\n",
    "        |> slurm_utils `Contails helper files for distributed training using tensorflow`\n",
    "    |> train.py `Main File used to train the model`\n",
    "    |> models.py `Contains architecture of the model we are training.`\n",
    "    |> config.py `Configuration file`\n",
    "    |> config.json `Configuration file`\n",
    "|> data `Contains training and validation data`\n",
    "|> train_job.sh `main batch file`\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14cf13a-137d-4f5c-b2cd-610b95371b63",
   "metadata": {},
   "source": [
    "## Create virtual environment\n",
    "We will use the python from conda environment to create a virtual environment which will be used throughout.\n",
    "\n",
    "In some cases conda might not be activated after installation. You can just refresh your bash terminal using `exec bash` and it should enable the conda environment for you.\n",
    "\n",
    "Once in the conda environment, you can create a new python virtual environment using `python -m venv .venv`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b857057d-6d7c-4a6d-b283-875a8eee8efe",
   "metadata": {},
   "source": [
    "## Update configuration and environment variables\n",
    "\n",
    "In `config.json` file change all instances of `<username>` with the user name provided to you.\n",
    "\n",
    "In the `train_job.sh` file update instances of `<username>` with the user name provided to you.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c66691-001e-46a6-882d-9702814d77d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat /p/project/training2206/<username>/train_job.sh "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d17936-ef79-4293-9d2d-74b2a60557ea",
   "metadata": {},
   "source": [
    "# Submit training job\n",
    "In the `train_job.sh` we can specify the number of nodes we want to use for training. As an example we are going to use 2 nodes for training. \n",
    "\n",
    "We can submit the training job using the `sbatch` command. Like so: `sbatch train_job.sh`\n",
    "\n",
    "Once submitted, two new files will be created by the process: `output.out` and `error.err`. `output.out` will contain details of output from our processes and `error.err` will detail out any errors from the scripts. Once the job is submitted and the files are created, we can check for updates simply by using `tail -f output.out error.err`.  (Any warnings/automated messages/errors are tracked in the `error.err` file while only the "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9a1f02",
   "metadata": {},
   "source": [
    "# Uploading the model to a cloud environment\n",
    "\n",
    "After the model is finished training, the model is stored in the location specified in your config file `/p/project/training2206/<username>/pixel-detector/models/<username>_smoke_wmts_ref_3layer.h5`. We will be taking this model and push it to a S3 bucket using `boto3` and the credentials from the aws account shared with you.\n",
    "\n",
    "## Get AWS credentials\n",
    "Account creation links should have been shared with all. Once the account is setup, we will gather the credentials required for upload from the AWS SSO homepage.\n",
    "Please follow the steps listed below:\n",
    "\n",
    "1. Navigate to https://nasa-impact.awsapps.com/start\n",
    "2. Login\n",
    "3. Click on `AWS Account`\n",
    "4. Click on `summerSchool`\n",
    "5. Click on `Command line or Programmatic access`\n",
    "6. Copy the `AWS Access Key Id`, `AWS Secret Access Key`, and `AWS session token` from the pop up\n",
    "7. Update the following script and run it.\n",
    "\n",
    "This will upload the files directly into the S3 bucket. We will then fetch the file from S3 bucket into the sagemaker notebook from where we will be deploying the model and hosting an API to interact with the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9503e011",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3 \n",
    "\n",
    "\n",
    "AWS_ACCESS_KEY_ID = <Copied over from sso login>\n",
    "AWS_SECRET_ACCESS_KEY = <Copied over from sso login>\n",
    "AWS_SESSION_TOKEN = <Copied over from sso login>\n",
    "\n",
    "BUCKET_NAME = 'smoke-dataset-bucket'\n",
    "\n",
    "def generate_federated_session():\n",
    "    \"\"\"\n",
    "    Method to generate federated session to upload the file from HPC to S3 bucket.\n",
    "    ARGs:\n",
    "        filename: Upload filename\n",
    "    Returns: \n",
    "        Signed URL for file upload \n",
    "    \"\"\"\n",
    "    return boto3.session.Session(\n",
    "            aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
    "            aws_secret_access_key=AWS_SECRET_ACCESS_KEY,\n",
    "            aws_session_token=AWS_SESSION_TOKEN\n",
    "        )\n",
    "\n",
    "model_filename = \"/p/project/training2206/<username>/pixel-detector/models/\"\n",
    "session = generate_federated_session()\n",
    "s3_connector = session.client('s3')\n",
    "\n",
    "s3_connector.upload_file(model_filename, BUCKET_NAME, \"<username>/<username>_smoke_wmts_ref_3layer.h5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c67866e",
   "metadata": {},
   "source": [
    "Once the process is done, we can check for the files in s3 using the AWS console.\n",
    "\n",
    "1. Navigate to https://nasa-impact.awsapps.com/start\n",
    "2. Login\n",
    "3. Click on `AWS Account`\n",
    "4. Click on `summerSchool`\n",
    "5. Click on `Management Console`\n",
    "6. In the search bar, search for `s3`\n",
    "7. Click on `s3`\n",
    "8. Click on `smoke-dataset-bucket`\n",
    "9. Click on your `username`\n",
    "\n",
    "You should be able to view your file there now. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
